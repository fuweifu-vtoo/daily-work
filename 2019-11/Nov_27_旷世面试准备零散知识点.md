Nov_27_旷世面试准备零散知识点

1. 模型训练过程中出现nan值怎么处理?
	- 如果不是模型代码和数据集的问题,则可以重新初始化
	- 梯度截断,使用relu6
	- 查看分母是否为0
	- 重新清理数据集
	- 减小学习率

2. 训练时/fine-tune时的学习率trick : Warmup预热学习率.

3. 什么是Warmup预热学习率:它在训练开始的时候先选择使用一个较小的学习率，训练了一些epoches或者steps(比如4个epoches,10000steps),再修改为预先设置的学习来进行训练。

4. 当显存过小时,使用平均损失来求梯度,防止单次样本太小而震荡剧烈.

5. 对于负样本主导loss问题:
	- 对数据集重采样resample
	- 使用带权重的交叉熵损失函数
	- 对于focal loss 而言,是应该添加 alpha,alpha为0.25

6. 难例样本挖掘问题(负样本主导loss问题):
	- 对于 focal loss而言,是因该添加 gamma,gamma为2
	- 使用ohem.ohem通过丢弃easy example 实现难例样本挖掘,将比例控制在1:3,留下来的3的负样本都是难例样本了,也可以理解为比较有代表性的样本.(focal loss没有丢弃负样本)

7. 过拟合怎么解决:
	- 获取和使用更多的数据集,数据增强和数据多样化
	- 使用 Dropout
	- 正则化(L1,L2正则化)   !!![重要]
	- Early Stopping
	- 交叉验证等