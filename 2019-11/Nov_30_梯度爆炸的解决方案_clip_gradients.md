Nov_30_梯度爆炸的解决方案_clip_gradients
====
1. 通常会使用一种叫”clip gradients “的方法. 它能有效地权重控制在一定范围之内.算法步骤如下:
	- 首先设置一个梯度阈值：clip_gradient
	- 在后向传播中求出各参数的梯度，这里我们不直接使用梯度进去参数更新，我们求这些梯度的l2范数
	- 然后比较梯度的l2范数||g||与clip_gradient的大小
	- 如果前者大，求缩放因子clip_gradient/||g||,　由缩放因子可以看出梯度越大，则缩放因子越小，这样便很好地控制了梯度的范围
	- 最后将梯度乘上缩放因子便得到最后所需的梯度

2. 梯度截断这部分是要求缩放因子clip_gradient/||g||的,而不是直接截断.
3. 有无clip_gradient在GRU模型中的结果比较
	- 无clip_gradient,可以很清楚地发现在2000次迭代出发生了梯度爆炸，最终影响了训练的效果。
	- 有clip_gradient,可以发现clip_gradient在前期有效了控制了梯度爆炸的影响，使得最终的loss能下降到满意的结果